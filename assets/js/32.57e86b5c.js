(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{490:function(o,e,_){"use strict";_.r(e);var p=_(12),v=Object(p.a)({},(function(){var o=this,e=o.$createElement,_=o._self._c||e;return _("ContentSlotsDistributor",{attrs:{"slot-key":o.$parent.slotKey}},[_("h1",[o._v("介绍")]),o._v(" "),_("p",[o._v("Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。")]),o._v(" "),_("p",[o._v("Sqoop项目开始于2009年，最早是作为Hadoop的一个第三方模块存在，后来为了让使用者能够快速部署，也为了让开发人员能够更快速的迭代开发，Sqoop独立成为一个Apache项目。")]),o._v(" "),_("h1",[o._v("软件获取")]),o._v(" "),_("pre",[_("code",[o._v("wget http://apache.01link.hk/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz")])]),o._v(" "),_("h1",[o._v("安装前准备")]),o._v(" "),_("ul",[_("li",[o._v("安装hadoop")]),o._v(" "),_("li",[o._v("安装hive")]),o._v(" "),_("li",[o._v("安装hbase")])]),o._v(" "),_("h1",[o._v("安装")]),o._v(" "),_("pre",[_("code",[o._v("tar xvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz -C /opt/\n"),_("p",[o._v("ln -s sqoop sqoop-1.4.7.bin__hadoop-2.6.0")])])]),o._v(" "),_("h1",[o._v("环境变量配置")]),o._v(" "),_("pre",[_("code",[o._v("# JAVA环境变量\nexport JAVA_HOME=/opt/jdk1.8.0_121\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.😒{JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH"),_("p"),o._v("\n"),_("h1",{attrs:{id:"hadoop环境变量"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#hadoop环境变量"}},[o._v("#")]),o._v(" hadoop环境变量")]),o._v("\n"),_("p",[o._v('export HADOOP_HOME=/opt/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin\nexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native\nexport HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR"')]),o._v("\n"),_("h1",{attrs:{id:"hive环境变量"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#hive环境变量"}},[o._v("#")]),o._v(" hive环境变量")]),o._v("\n"),_("p",[o._v("export HIVE_HOME=/opt/hive\nexport PATH=$PATH:$HIVE_HOME/bin")]),o._v("\n"),_("h1",{attrs:{id:"sqoop环境变量"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#sqoop环境变量"}},[o._v("#")]),o._v(" sqoop环境变量")]),o._v("\n"),_("p",[o._v("export HADOOP_COMMON_HOME=/opt/hadoop\nexport HADOOP_MAPRED_HOME=/opt/hadoop\nexport SQOOP_HOME=/opt/sqoop\nexport PATH=$PATH:$SQOOP_HOME/bin")])])]),o._v(" "),_("h1",[o._v("测试")]),o._v(" "),_("pre",[_("code",[o._v("sqoop version"),_("p"),o._v("\n"),_("p",[o._v("18/07/02 15:22:02 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7\nSqoop 1.4.7\ngit commit id 2328971411f57f0cb683dfb79d19d4d19d185dd8\nCompiled by maugli on Thu Dec 21 15:59:58 STD 2017")])])]),o._v(" "),_("h1",[o._v("下载mysql-connector")]),o._v(" "),_("pre",[_("code",[o._v("# 将下载解压后的jar包拷贝到/opt/sqoop/lib目录下\nwget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz")])]),o._v(" "),_("h1",[o._v("FAQ")]),o._v(" "),_("ul",[_("li",[o._v("HADOOP_CLASSPATH引发的异常")])]),o._v(" "),_("pre",[_("code",[o._v("ERROR hive.HiveConfig: Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is set correctly.")])]),o._v(" "),_("p",[o._v("解决方案：")]),o._v(" "),_("pre",[_("code",[o._v("# 根据具体使用的bash进行相应设置\nvi ~/.zshrc"),_("p"),o._v("\n"),_("p",[o._v("export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/opt/hive/lib/*")]),o._v("\n"),_("p",[o._v("source ~/.zshrc")])])]),o._v(" "),_("ul",[_("li",[o._v("JDK权限引发的异常")])]),o._v(" "),_("pre",[_("code",[o._v('ERROR Could not register mbeans java.security.AccessControlException: access denied ("javax.management.MBeanTrustPermission" "register")')])]),o._v(" "),_("p",[o._v("解决方案：")]),o._v(" "),_("pre",[_("code",[o._v("vi /opt/jdk/jre/lib/security/java.policy"),_("p"),o._v("\n"),_("p",[o._v('grant {\n...\npermission javax.management.MBeanTrustPermission "register";\n}')])])]),_("p")])}),[],!1,null,null,null);e.default=v.exports}}]);